Yolo instructions

############# FOR IMAGEAI DATASET - YOLOV3 DATASET
###### TRAINING 
Run, custom detection training:
	from imageai.Detection.Custom import DetectionModelTrainer

	trainer = DetectionModelTrainer()
	trainer.setModelTypeAsYOLOv3()
	trainer.setDataDirectory(data_directory="Z:\DeepLabCut\misc\imageAI\data")
	trainer.setTrainConfig(object_names_array=["White_mouse", "Black_mouse"], batch_size=4, num_experiments=50, train_from_pretrained_model="pretrained-yolov3.h5")
	trainer.trainModel()

############# CLASSIFY VIDEO
###### DETECTION
Run, custom detection video:

	from imageai.Detection.Custom import CustomVideoObjectDetection
	import os

	execution_path = os.getcwd()

	video_detector = CustomVideoObjectDetection()
	video_detector.setModelTypeAsYOLOv3()
	video_detector.setModelPath("detection_model-ex-023--loss-4.142.h5") # download via https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/hololens-ex-60--loss-2.76.h5
	video_detector.setJsonPath("Z:\DeepLabCut\misc\imageAI\data\json\detection_config.json") # download via https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/detection_config.json
	video_detector.loadModel()

	video_detector.detectObjectsFromVideo(input_file_path="Video53_ds_2.mp4",
                                          output_file_path=os.path.join(execution_path, "Video53_tracked"),
                                          frames_per_second=80,
                                          minimum_percentage_probability=40,
                                          log_progress=True)

############# CLASSIFY IMAGES
###### DETECTION
Run, custom detection:

	from imageai.Detection.Custom import CustomObjectDetection

	detector = CustomObjectDetection()
	detector.setModelTypeAsYOLOv3()
	detector.setModelPath("detection_model-ex-023--loss-3.416.h5") # download via https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/hololens-ex-60--loss-2.76.h5
	detector.setJsonPath("Z:\DeepLabCut\misc\imageAI\data\json\detection_config.json") # download via https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/detection_config.json
	detector.loadModel()

	detections = detector.detectObjectsFromImage(input_image="1000035_2.png", output_image_path="1000035_2_detected.jpg")
	for detection in detections:
    		print(detection["name"], " : ", detection["percentage_probability"], " : ", detection["box_points"])


Mask RCNN instructions.

If using labelme:
	Convert .json / images generated by labelme to coco:
		python labelme2coco.py "Z:/DeepLabCut/misc/images_for_coco/entire_body/train" "Z:/DeepLabCut/misc/tensorflow/labelme2coco/output_coco" --labels body_parts_all.txt
		Use modified labelme2coco.py (modified to work in Windows). Backup located in at: "Z:\Golden_Lab_Users\Nilsson_Simon\backup\labelme2coco.py"
	Convert coco.json to tf_record:
		python create_coco_tf_record_from_labelme_coco.py
		Use modified create_coco_tf_record (modified to handle segmenets = 4, confused with bbbox, and standard bbox sizes). Backup located at: "Z:\Golden_Lab_Users\Nilsson_Simon\backup\create_coco_tf_record_from_labelme_coco.py"
	Run RCC training:
		python model_main.py --logtostderr
		Use labelmap.pbtxt, pipeline.config, and model_main in this path: Z:\Golden_Lab_Users\Nilsson_Simon\backup\mask_rcnn_labelme
		Manually create: \train\export\Servo	

Using polyglon labelling interface:
	Initate polyglon labelling interface:
		python -m coco_dataset_generator.gui.segment -i "Z:/DeepLabCut/misc/images_for_coco" -c classes/heads.txt
	Create combinedcoco.json from txt label info files:
		python -m coco_dataset_generator.utils.create_json_file -i "Z:\DeepLabCut\misc\images_for_coco_train" -c classes/heads.txt -o heads_train -t png
		Software backup at: "Z:\Golden_Lab_Users\Nilsson_Simon\backup\COCO-Style-Dataset-Generator-GUI-master"
	Convert coco.json to tf_record:
		python create_coco_tf_record.py
		Modied to handle the classes names and the bboxes and 4 values rather than 2. Backup at: "Z:\Golden_Lab_Users\Nilsson_Simon\backup\create_coco_tf_record_train.py"
	Run RCC training:
		python model_main.py --logtostderr
		Use labelmap.pbtxt, pipeline.config, and model_main in this path: Z:\Golden_Lab_Users\Nilsson_Simon\backup\mask_rcnn_labelme
		Manually create: \train\export\Servo
		Modify the labelmap.pbtxt and the pipeline config (number of classes) to fit. 
	
#CREATE INFERENCE GRAPH
python export_inference_graph.py

#CREATE PBTXT
python generate.py --input="Z:/DeepLabCut/misc/tensorflow/coco_project_heads/inception_coco/frozen_whole_body\frozen_inference_graph_100719.pb" --output="Z:/DeepLabCut/misc/tensorflow/coco_project_heads/inception_coco/frozen_whole_body/coco.pbtxt" --config="Z:/DeepLabCut/misc/tensorflow/coco_project_heads/inception_coco/mask_rcnn_inception_v2_coco.config"
(needs generate.py and tf_text_graph_common.py in same folder)




#RUN MODEL ON A NEW IMAGE
python mask_rcnn.py

#RUN TENSORBORD, does not work in chrome (edge works)
tensorboard --logdir="Z:/DeepLabCut/misc/tensorflow/coco_project_heads/inception_coco/models/train"


#LABELME2COCO
python3 labelme2coco.py "Z:/DeepLabCut/misc/images_for_coco/entire_body/train" "Z:/DeepLabCut/misc/tensorflow/labelme2coco/output_coco" --labels body_parts_all.txt








